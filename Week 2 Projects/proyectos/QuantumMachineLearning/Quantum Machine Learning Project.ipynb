{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Machine Learning Project\n",
    "\n",
    "### Team members:\n",
    "* Alan Vásquez\n",
    "* Ángel Álvarez\n",
    "* María Linares\n",
    "* Jaissar Cammarata\n",
    "* Luis Villoria\n",
    "* Milagro Roja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4mfeqKsV7JAh"
   },
   "outputs": [],
   "source": [
    "from qiskit import  Aer\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.aqua.algorithms import VQC\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "from qiskit.circuit.library import TwoLocal, PauliFeatureMap\n",
    "from qiskit.aqua.utils import  map_label_to_class_name\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import *\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_7N9LQeCwVG"
   },
   "outputs": [],
   "source": [
    "seed = 7777\n",
    "algorithm_globals.random_seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyGZjIKcCIV1"
   },
   "source": [
    "# Data import and first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZzMsu69cCHAw"
   },
   "outputs": [],
   "source": [
    "# We read out the files and see what are they composed\n",
    "test_df = pd.read_csv(r'mock_test_set.csv', delimiter=',') \n",
    "train_df = pd.read_csv(r'mock_train_set.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "vLr0F8jUCKzu",
    "outputId": "25582070-939a-46a5-e00d-271d132cd6fa"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "eGriPfb-CMYk",
    "outputId": "6cdb2861-fd42-413e-b865-c4829fba856a"
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6lWtr78vCN0l"
   },
   "outputs": [],
   "source": [
    "train_labels = train_df['4'].values.tolist()\n",
    "train_data = train_df[['0','1','2','3']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xhtl4wBzJihy"
   },
   "outputs": [],
   "source": [
    "test_labels = test_df['4'].values.tolist()\n",
    "test_data = test_df[['0','1','2','3']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "VawCmzLwqD2L",
    "outputId": "a724e41b-851c-4aca-b63d-9ad536f68fc5"
   },
   "outputs": [],
   "source": [
    "train_df.plot(subplots=True, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "gU2LkyiVr3RC",
    "outputId": "6924e976-fed9-4efd-cbb4-bd6df0cf4dbf"
   },
   "outputs": [],
   "source": [
    "test_df.plot(subplots=True, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmQDcA2LQdNX"
   },
   "source": [
    "# Normalization and separation of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLfSz3RAK6u7"
   },
   "outputs": [],
   "source": [
    "n_train = len(train_data)\n",
    "n_test = len(test_data)\n",
    "\n",
    "feature_dim = len(test_data[0])\n",
    "\n",
    "# Separation of the data for zero's and one's\n",
    "one_train = []\n",
    "zero_train = []\n",
    "\n",
    "for i in range(n_train):\n",
    "    if train_labels[i] == 0:\n",
    "        zero_train.append(train_data[i])\n",
    "    else:\n",
    "        one_train.append(train_data[i])\n",
    "\n",
    "one_test = []\n",
    "zero_test = []\n",
    "\n",
    "for i in range(n_test):\n",
    "    if test_labels[i] == 0:\n",
    "        zero_test.append(test_data[i])\n",
    "    else:\n",
    "        one_test.append(test_data[i])\n",
    "\n",
    "# Normalization\n",
    "np.linalg.norm(zero_train)\n",
    "zero_train_n  =  [ [ i/np.linalg.norm(j)  for i in j ] for j in zero_train ]\n",
    "one_train_n = [ [ i/np.linalg.norm(j)  for i in j ] for j in one_train ]\n",
    "        \n",
    "zero_test_n  = [ [ i/np.linalg.norm(j)  for i in j ] for j in zero_test ]\n",
    "one_test_n  = [ [ i/np.linalg.norm(j)  for i in j ] for j in one_test ]\n",
    "\n",
    "# Reduction of size and creation of the valition set from the train set.\n",
    "size_train = 0.9 # 90% of the train set\n",
    "size_test = 1 # 100% of the train set\n",
    "size_val = 0.1 #10% of the train set for validation set\n",
    "zero_train_r, zero_val, _ = np.split(zero_train_n,[ int(len(zero_train_n)*size_train), int(len(zero_train_n)*(size_train+size_val))])\n",
    "one_train_r, one_val, _ = np.split(one_train_n,[ int(len(one_train_n)*size_train), int(len(one_train_n)*(size_train+size_val))])\n",
    "\n",
    "zero_test_r = zero_test_n[:int(len(zero_test_n)*size_test)]\n",
    "one_test_r = one_test_n[:int(len(one_test_n)*size_test)]\n",
    "\n",
    "# Division in classes for each data set\n",
    "training_input = {'A':zero_train_r, 'B':one_train_r}\n",
    "test_input = {'A':zero_test_r, 'B':one_test_r}\n",
    "\n",
    "# Validation set\n",
    "datapoints = []\n",
    "datapoints.append(np.concatenate((zero_val, one_val)))\n",
    "labels = np.concatenate(([0 for _ in range(len(zero_val))], [1 for _ in range(len(one_val))]))\n",
    "datapoints.append(labels)\n",
    "\n",
    "class_to_label = {'A':0, 'B':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Datapoints for training: {len(zero_train_r)+len(one_train_r)}\")\n",
    "print(f\"Datapoints for testing: {len(zero_test_r)+len(one_test_r)}\")\n",
    "print(f\"Datapoints for validation: {len(zero_val)+len(one_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PWfbBHMQf-k"
   },
   "source": [
    "# Feature Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAmW5IEoQfvL"
   },
   "outputs": [],
   "source": [
    "# The more general and arbitrary feature map available is the Paule Feature Map changing the paulis parameters\n",
    "pauli_fm = PauliFeatureMap(feature_dimension=feature_dim, reps=2, paulis=[['Z','X','ZY']],entanglement='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XXXo0FjQiIk"
   },
   "source": [
    "# VQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FM9OwDsnQize"
   },
   "outputs": [],
   "source": [
    "two = TwoLocal(feature_dim, ['ry'],'cx', reps=2, entanglement='full')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAuuX_QFQjy_"
   },
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_intermediate_result(evaluation, parameter, cost, stepsize, accept):\n",
    "    \"\"\"\n",
    "    This function receives the intermediate values of the optimizer and saves the cost values to plot them \n",
    "    in a future.\n",
    "    \"\"\"\n",
    "    costs.append(cost)\n",
    "    parameters.append(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJU-fEz8Qkwh"
   },
   "outputs": [],
   "source": [
    "# We select the SPSA optimizer since is the optimal optimizer for large population of values\n",
    "spsa = SPSA(maxiter=40, callback=store_intermediate_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TmqHRXQQnfV"
   },
   "source": [
    "# Circuit Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCuJJ_vOQnxT"
   },
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('qasm_simulator')\n",
    "backend_op =  {'method':'statevector'}\n",
    "quantum_instance = QuantumInstance(backend, shots=1024, seed_simulator=seed, seed_transpiler=seed, backend_options=backend_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aux functions\n",
    "\n",
    "def test_accuracy(actual, predicted):\n",
    "    \"\"\"\n",
    "    This function calculates the accuracy between the prection classes and the actual classes.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct = correct+1\n",
    "            \n",
    "    return correct/len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store values for one repetion of each fm and vqc\n",
    "\n",
    "result_data = {}\n",
    "\n",
    "fm = pauli_fm\n",
    "varqc = two\n",
    "\n",
    "# This list will fill in the evaluation of the VQC\n",
    "counts = []\n",
    "costs = []\n",
    "parameters = []\n",
    "\n",
    "# Build of the VQC circuit\n",
    "vqc = VQC(optimizer=spsa, feature_map=fm, var_form=varqc, training_dataset=training_input, test_dataset=test_input,datapoints=datapoints[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Execution of the VQC\n",
    "result = vqc.run(quantum_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the final prediction of the VQC circuit\n",
    "actual = map_label_to_class_name(datapoints[1], vqc.label_to_class)\n",
    "predicted = result['predicted_classes']\n",
    "\n",
    "# Calculation of the accuracy values, final accuracy of the VQC and the Confusion matrix metrics report.\n",
    "accuracy = []\n",
    "final_accuracy = test_accuracy(actual, predicted)\n",
    "conf_mat = classification_report(actual, predicted, labels=['A','B'])\n",
    "\n",
    "\n",
    "# Save of the results of these data\n",
    "result_data = {\n",
    "    'parameters': parameters,\n",
    "    'costs': costs,\n",
    "    'accuracy_vals':accuracy,\n",
    "    'result' : result,\n",
    "    'final_accuracy' : final_accuracy,\n",
    "    'confusion_matrix' : conf_mat,\n",
    "    'actual' : actual,\n",
    "    'predicted' : predicted\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(result_data['costs'])\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost function')\n",
    "plt.title('Cost function vs Iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_data['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_data['final_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
